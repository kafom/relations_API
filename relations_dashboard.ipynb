{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import math\n",
    "import csv\n",
    "from alchemyapi import AlchemyAPI\n",
    "\n",
    "def open_json_review_files(cruiseLines):\n",
    "    \"\"\"\n",
    "    creates dictionary with one or more cruise lines review json files\n",
    "    \"\"\"\n",
    "    lineDb= {}\n",
    "    commentDb = {}\n",
    "    totcount = 0\n",
    "    for line in cruiseLines:\n",
    "        count = 0\n",
    "        with open('data/'+line+'.json', 'rb') as fp:\n",
    "            lineDb[line] = json.load(fp)\n",
    "            commentDb.update(lineDb)\n",
    "            for element in commentDb[line]:\n",
    "                count = count + 1 \n",
    "        totcount=totcount+count\n",
    "        print \"processed\", line, len(commentDb[line]),\"reviews\"\n",
    "    print 'total processed', totcount, 'reviews'\n",
    "    return commentDb\n",
    "\n",
    "def cleanRatings(commentDb,cruiseLines):\n",
    "    \"\"\"\n",
    "    cleans up and aggregates ratings data\n",
    "    \"\"\"\n",
    "    ratingAggregations={\"6\":\"good\",\"5\":\"good\",\"4\":\"medium\",\"3\":\"medium\",\"2\":\"bad\",\"1\":\"bad\",\"no rating\":\"no rating\"}\n",
    "    count = 0 \n",
    "    for line in cruiseLines:\n",
    "        for element in commentDb[line]:\n",
    "            if len(commentDb[line][element][\"kind\"]) <5:\n",
    "                   commentDb[line][element][\"kind\"]=\"not specified\"\n",
    "            if not commentDb[line][element][\"rating\"].isdigit():\n",
    "                    commentDb[line][element][\"rating\"]=\"no rating\" \n",
    "            if len(commentDb[line][element][\"ship\"]) <5:\n",
    "                    commentDb[line][element][\"ship\"]=\"not available\"                     \n",
    "            commentDb[line][element][\"aggregatedRating\"]=ratingAggregations[commentDb[line][element][\"rating\"]] \n",
    "    return commentDb\n",
    "\n",
    "def checkDailyQuotaAndRunAlchemy(commentDb,cruiseLines):\n",
    "    with open('data/Alchemy_response_keywords.json', 'rb') as fp:\n",
    "            returned_keywords = json.load(fp)\n",
    "    with open('data/Alchemy_response_relations.json', 'rb') as fp:\n",
    "            returned_relations = json.load(fp)       \n",
    "    alchemyapi = AlchemyAPI()\n",
    "    test=\"test if finished Alchemy daily quota\"\n",
    "    response = alchemyapi.keywords('text', test, {'sentiment': 0})\n",
    "    if response['status'] == 'OK':\n",
    "        returned_keywords,returned_relations=runAlchemyApi(cruiseLines,commentDb,returned_keywords,returned_relations,alchemyapi)\n",
    "    else:\n",
    "        print 'Error in keyword extraction call: ', response['statusInfo']\n",
    "    return returned_keywords, returned_relations \n",
    "\n",
    "def runAlchemyApi(cruiseLines, commentDb,returned_keywords,returned_relations,alchemyapi):\n",
    "    count_keywords=0\n",
    "    count_relations=0\n",
    "    check=0\n",
    "    low_ratings={\"1\",\"2\",\"5\",\"6\"}    \n",
    "    print \"getting Alchemy keyword data. We already have keywords of \", len(returned_keywords),\"reviews\"\n",
    "    for line in cruiseLines:\n",
    "        for element in commentDb[line]:\n",
    "            text=commentDb[line][element][\"comment\"]\n",
    "            if element in returned_keywords or len(text) <100:\n",
    "                pass\n",
    "            else:\n",
    "                response = alchemyapi.keywords('text', text, {'sentiment': 1})\n",
    "                call=\"keywords\"\n",
    "                if response['status'] == 'OK':\n",
    "                    returned_keywords=load_element_data(call,response,returned_keywords,commentDb,element,line)            \n",
    "                    count_keywords=count_keywords+1\n",
    "                else:\n",
    "                    print 'Error in keyword extaction call: ', response['statusInfo']\n",
    "                    break                      \n",
    "            if commentDb[line][element]['rating'] in low_ratings:\n",
    "                if element in returned_relations or len(text) <100:\n",
    "                    pass\n",
    "                else:\n",
    "                    response = alchemyapi.relations('text', text, {'sentiment': 1})\n",
    "                    call=\"relations\"\n",
    "                    if response['status'] == 'OK' :\n",
    "                        count_relations=count_relations+1 \n",
    "                        returned_relations==load_element_data(call,response,returned_relations,commentDb,element,line)    \n",
    "                    else:\n",
    "                        print 'Error in keyword extaction call: ', response['statusInfo']\n",
    "                        break  \n",
    "    print \"finished getting keyword data from Alchemy for\", count_keywords,\"reviews\"        \n",
    "    print \"in total we have got keyword data for\", len(returned_keywords),\"reviews\"\n",
    "    print \"finished getting relations data from Alchemy for\", count_relations,\"reviews\"        \n",
    "    print \"in total we have got relations data for\", len(returned_relations),\"reviews\"        \n",
    "    save_dictionary(returned_keywords,\"keywords\")\n",
    "    save_dictionary(returned_relations,\"relations\")    \n",
    "    return returned_keywords, returned_relations\n",
    "\n",
    "def load_element_data(call,response,returned_dictionary,commentDb,element,line):   \n",
    "    returned_dictionary[element]={}\n",
    "    returned_dictionary[element]=response\n",
    "    returned_dictionary[element][\"rating\"]=commentDb[line][element]['rating']\n",
    "    returned_dictionary[element]['ship']=commentDb[line][element]['ship']\n",
    "    returned_dictionary[element]['sail_date']=commentDb[line][element]['sail Date']\n",
    "    returned_dictionary[element]['line']=line\n",
    "    return returned_dictionary\n",
    "\n",
    "def save_dictionary(returned_dictionary,call):\n",
    "    with open('data/Alchemy_response_'+call+'.json', 'wb') as fp:\n",
    "        json.dump(returned_dictionary, fp) \n",
    "                     \n",
    "def make_keywords_csv_alchemy(returned_keywords,commentDb):\n",
    "    \"\"\"\n",
    "    generates the csv file that powers the keyword dashboard\n",
    "    \"\"\"\n",
    "    call=\"keywords\"\n",
    "    df=clean_dictionary_keys(returned_keywords,call,commentDb)\n",
    "    patterns = [(r'[^A-Za-z0-9 ]+',''),(r' +',' ')]\n",
    "    regex_columns=[\"Word\"]\n",
    "    df=clean_with_regex(regex_columns,patterns,df)    \n",
    "    columns=[\"Word\"]\n",
    "    make_lowercase(columns,df)\n",
    "    mask=df.Word.str.len() >= 2\n",
    "    df=delete_useless_rows(mask,df)   \n",
    "    mask=df.Rating!=\"no rating\"\n",
    "    df=delete_useless_rows(mask,df)  \n",
    "    to_float=[\"relevance\",\"sentiment_score\",\"Rating\"]\n",
    "    df=convert_to_float(to_float, df)\n",
    "    minimum_scores={\"standard\":0.50,\"high\":0.6,\"very_high\":0.7}\n",
    "    for hypothesis in minimum_scores:\n",
    "        filter_data_and_generate_hypothesis(df,hypothesis,minimum_scores)        \n",
    "        \n",
    "def make_relations_csv_alchemy(returned_relations,commentDb):\n",
    "    \"\"\"\n",
    "    generates the csv file that powers the relations dashboard\n",
    "    \"\"\"\n",
    "    call=\"relations\"\n",
    "    df=clean_dictionary_keys(returned_relations,call,commentDb)\n",
    "    patterns = [(r'[^A-Za-z0-9%\\' ]+',''),(r' +',' ')]\n",
    "    text_columns=[\"sbjText\",\"actText\", \"objText\",\"location.text\"]\n",
    "    df=clean_with_regex(text_columns,patterns,df)\n",
    "    make_lowercase(text_columns,df)\n",
    "    to_float=[\"sbjSentScore\",\"objSentScore\",\"object.sentimentFromSubject.score\",\"location.sentiment.score\"]\n",
    "    df=convert_to_float(to_float, df)    \n",
    "    save_csv(df,call)   \n",
    "\n",
    "def clean_dictionary_keys(returned_dictionary,call,commentDb):\n",
    "    line=cruiseLines[0]\n",
    "    df=pd.DataFrame()\n",
    "    count_keywords=0\n",
    "    count_relations=0\n",
    "    keys_to_drop=[\"language\",\"status\",\"usage\",\"totalTransactions\",\"url\"]\n",
    "    to_rename=  {\"keywords\":{\"text\":\"Word\",'relevance_x': 'relevance','sentiment.score': 'sentiment_score',\n",
    "        \"sentiment\":\"dictionary\",'sentiment.type': 'Sentiment',\"rating\":\"Rating\",\"ship\":\"Ship\",\"line\":\"Line\"},\n",
    "        \"relations\":{\"action.lemmatized\":\"actLemma\",\n",
    "                     \"action.text\":\"actText\",\n",
    "                     \"action.verb.negated\":\"actVerbNeg\",\n",
    "                     \"action.verb.text\":\"actVerbText\",\n",
    "                     \"object.sentiment.score\":\"objSentScore\",\n",
    "                     \"object.sentiment.type\":\"objSentType\",\n",
    "                     \"object.text\":\"objText\",\n",
    "                     \"subject.sentiment.score\":\"sbjSentScore\",\n",
    "                     \"subject.sentiment.type\":\"sbjSentType\",\n",
    "                     \"subject.text\":\"sbjText\"           \n",
    "                     }}\n",
    "    for review in returned_dictionary:\n",
    "        if call == \"relations\":\n",
    "            count_relations=count_relations+1\n",
    "            if count_relations % 500 == 0:    \n",
    "                print \"finished\", count_relations,\"out of\",len(returned_dictionary)\n",
    "        else:\n",
    "            count_keywords=count_keywords+1\n",
    "            if count_keywords % 500 == 0:    \n",
    "                print \"finished\", count_keywords,\"out of\",len(returned_dictionary)\n",
    "        if returned_dictionary[review][\"language\"]!=\"english\":\n",
    "            print review, \"review seems not to be in English, but in\", returned_dictionary[\"language\"]\n",
    "        for key in keys_to_drop:\n",
    "            returned_dictionary[review].pop(key, None)\n",
    "        else:\n",
    "            df=flatten_dictionary(returned_dictionary,review,call,df,commentDb,line)\n",
    "    df.rename(columns=to_rename[call], inplace=True)\n",
    "    return df\n",
    "\n",
    "def clean_with_regex(regex_columns,patterns,df):\n",
    "    for column in regex_columns:\n",
    "        for pattern in patterns:\n",
    "            df[column].replace(pattern[0],pattern[1], regex = True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def filter_data_and_generate_hypothesis(df,hypothesis,minimum_scores):        \n",
    "    min_relevance=minimum_scores[hypothesis]\n",
    "    min_sentiment=minimum_scores[hypothesis]\n",
    "    mask=df.relevance>=min_relevance\n",
    "    df=delete_useless_rows(mask,df)\n",
    "    df=change_unsure_to_neutral(min_sentiment,df)    \n",
    "    mask=df.Sentiment!=\"neutral\"\n",
    "    df=delete_useless_rows(mask,df)\n",
    "    df=aggregate_ratings(df)\n",
    "    mask=df.Rating!=\"medium\"\n",
    "    df=delete_useless_rows(mask,df) \n",
    "    mask=df.Line!=\"Costa\"\n",
    "    df=delete_useless_rows(mask,df) \n",
    "    df=reformat_dates(df)\n",
    "    to_drop=[\"sentiment_score\",\"relevance\",\"sail_date\",\"date\",\"dictionary\",\"relevance_y\",\"sentiment.mixed\"]\n",
    "    df=drop_columns(to_drop,df)    \n",
    "    to_add={\"count\":1}\n",
    "    df=add_columns(to_add,df)\n",
    "    df=make_pivot(df)\n",
    "    df[\"Total\"]=df[\"Positive\"]+df[\"Negative\"]\n",
    "    to_rename={\"rating\":\"Rating\"}\n",
    "    df.rename(columns=to_rename, inplace=True)\n",
    "    save_csv(df,hypothesis)\n",
    "\n",
    "def flatten_dictionary(returned_dictionary,review,call,df,commentDb,line): \n",
    "    if call == \"keywords\":\n",
    "        first_level=json_normalize(returned_dictionary[review],call,['rating','sail_date',\"ship\",\"line\"])\n",
    "        second_level=json_normalize(returned_dictionary[review][call])\n",
    "        together=pd.merge(first_level, second_level, on='text', how='outer')\n",
    "        df=pd.concat([df, together])\n",
    "    else:\n",
    "        if review in commentDb[\"Msc\"]:\n",
    "            rating=commentDb[\"Msc\"][review][\"rating\"]\n",
    "            for element in returned_dictionary[review][call]:\n",
    "                second_level=json_normalize(element)\n",
    "                second_level['review']=review\n",
    "                second_level['rating']=rating                \n",
    "                df=pd.concat([df,second_level])\n",
    "    return df \n",
    "\n",
    "\n",
    "def open_csv(suffix):\n",
    "    df= pd.DataFrame(pd.read_csv('data/alchemy_ratings_'+suffix+'.csv'))\n",
    "    return df\n",
    "\n",
    "def drop_columns(to_drop,df):    \n",
    "    for column in to_drop:\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def fill_na_columns(df,lista,fill_with):\n",
    "    for column in lista:\n",
    "        df[column].fillna(fill_with,inplace=True)\n",
    "        df[\"objSentScore\"].fillna(0,inplace=True)   \n",
    "    return df\n",
    "\n",
    "def reorder_column(df,new_list):\n",
    "    varlist =[w for w in df.columns if w not in new_list]\n",
    "    df = df[new_list+varlist]\n",
    "    return df \n",
    "\n",
    "\n",
    "def delete_useless_rows(mask,df):\n",
    "    df=df[mask]\n",
    "    return df\n",
    "\n",
    "def reformat_dates(df):\n",
    "    df[\"date\"]=pd.to_datetime(df.sail_date, format= \"%B %Y\", coerce= True)\n",
    "    df[\"Year\"]=pd.DatetimeIndex(df.date).year\n",
    "    return df\n",
    "\n",
    "def add_columns(to_add,df):                \n",
    "    for column in to_add:\n",
    "        df[column]=to_add[column]\n",
    "    return df\n",
    "\n",
    "def make_lowercase(columns,df):\n",
    "    for column in columns:\n",
    "        df[column]=df[column].str.lower()\n",
    "    return df\n",
    "\n",
    "def convert_to_float(to_float, df):\n",
    "    for column in to_float:\n",
    "        df[column]=df[column].astype(float).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "def change_unsure_to_neutral(min_sentiment,df):\n",
    "    df[\"Sentiment\"][(df[\"sentiment_score\"] <= min_sentiment) & (df[\"sentiment_score\"] >= -min_sentiment)]=\"neutral\"\n",
    "    return df\n",
    "\n",
    "def make_pivot(df):\n",
    "    df=df.reset_index()  \n",
    "    dataDims=[\"Word\",\"Rating\",\"Year\",\"Ship\",\"Line\"]\n",
    "    valueDims=[\"count\"]\n",
    "    columnDims=[\"Sentiment\"]\n",
    "    labels=['Negative','Positive']\n",
    "    pivotValues=preparePivotValues(columnDims,df)   \n",
    "    df=pd.pivot_table(df,values=valueDims,index=dataDims,columns=columnDims,aggfunc='sum').fillna(0)\n",
    "    result={}\n",
    "    for valueDim in valueDims:\n",
    "        result[valueDim]= df[valueDim]\n",
    "        print 'processing ', valueDim, ' valuedimension'        \n",
    "        result[valueDim] =renamePivotColumns(result[valueDim],labels,pivotValues[0]) \n",
    "        result[valueDim]=result[valueDim].reset_index()\n",
    "        print 'processing pivot with ', len(columnDims) ,' pivot column dimensions and ', len(valueDims),' value column dimensions.....'        \n",
    "    if len(columnDims) == 1 and len(valueDims) == 1:\n",
    "        df=result[valueDim]          \n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def renamePivotColumns(result,labels,dimensions):\n",
    "    count=0    \n",
    "    print \"CHECK THAT RENAMING IS CORRECT ==>\" \n",
    "    for dimension in dimensions:\n",
    "        print \"renamed \", dimension, \" as \", labels[count]                \n",
    "        result.rename(columns={dimension:labels[count]}, inplace=True) \n",
    "        count=count+1\n",
    "    print \"\\n \"    \n",
    "    return result    \n",
    "    \n",
    "    \n",
    "def preparePivotValues(columnDims,df):\n",
    "    pivotValues={}\n",
    "    count = 0    \n",
    "    for columnDim in columnDims:\n",
    "        pivotValues[count]=df[columnDims[count]].unique()\n",
    "        pivotValues[count].sort()\n",
    "        if (len(pivotValues[count]) != 2):\n",
    "            print 'More than two pivot values in a column. POSSIBLE ERROR IN DATA ==> ', pivotValues[count] \n",
    "        count = count + 1\n",
    "    print \"these are the pivot values \",pivotValues\n",
    "    return pivotValues    \n",
    "\n",
    "\n",
    "def prepare_keywords(sum_field,rating,suffix,top_number,line):\n",
    "    df=open_csv(suffix)\n",
    "    mask=df.Line==line\n",
    "    df=delete_useless_rows(mask,df)\n",
    "    mask=df.Rating==rating\n",
    "    df=delete_useless_rows(mask,df)\n",
    "    df=get_top_words(df,sum_field,top_number)\n",
    "    return df\n",
    "\n",
    "def get_top_words(df,sum_field,top_number):\n",
    "    df = df.groupby('Word')\n",
    "    df=df[sum_field].sum().order(ascending=False)\n",
    "    df=df.head(top_number).copy()\n",
    "    return df   \n",
    "\n",
    "def save_csv(df,hypothesis):\n",
    "    fileName='data/alchemy_ratings_'+hypothesis+'.csv'\n",
    "    print fileName  \n",
    "    df.to_csv(fileName,encoding='utf-8')\n",
    "\n",
    "def blank_out_short_sentences(df,blank_out_rules):\n",
    "    for rule in blank_out_rules:\n",
    "        df.loc[df[rule[0]].str.len() <=rule[1], rule[0]] = \"\"\n",
    "    return df    \n",
    "\n",
    "def make_top_dataframes(top_number,line):\n",
    "    \"\"\"\n",
    "    spits out top keywords used in negative reviews\n",
    "    \"\"\"\n",
    "    suffix=\"standard\"\n",
    "    top_neg_bad=prepare_keywords(\"Negative\",\"bad\",suffix,top_number,line)\n",
    "    top_neg_bad=top_neg_bad.reset_index()\n",
    "    return top_neg_bad\n",
    "\n",
    "def prepare_relations():\n",
    "    \"\"\"\n",
    "    gets cvs output from API relations call and \n",
    "    cleans it up for dc.js\n",
    "    \"\"\"\n",
    "    suffix=\"relations\"\n",
    "    df=open_csv(suffix)\n",
    "    df=df.drop_duplicates()\n",
    "    #blank_out_rules=((\"objText\",3),(\"sbjText\",3))\n",
    "    #df=blank_out_short_sentences(df,blank_out_rules)    \n",
    "    to_rename={\"object.sentimentFromSubject.score\":\"objSentFromSbjScore\",\n",
    "               \"object.sentimentFromSubject.type\":\"objSentFromSbjType\",\n",
    "               \"action.verb.tense\":\"actVerbTense\",\n",
    "               \"location.sentiment.score\":\"locSentScore\",\n",
    "               \"location.sentiment.type\":\"locSentType\",\n",
    "               \"location.text\":\"locText\"\n",
    "               }\n",
    "    df.rename(columns=to_rename, inplace=True)\n",
    "    fill_na_str=[\"objText\",\"sbjText\",\"actVerbText\",\"locText\"]\n",
    "    fill_with=\"\"\n",
    "    df=fill_na_columns(df,fill_na_str,fill_with)\n",
    "    fill_na_int=[\"actVerbNeg\",\"objSentScore\",\"objSentFromSbjScore\",\"sbjSentScore\",\"locSentScore\"]\n",
    "    fill_with=0\n",
    "    df=fill_na_columns(df,fill_na_int,fill_with) \n",
    "    fill_na_sent=[\"objSentType\",\"objSentFromSbjType\",\"sbjSentType\",\"locSentType\"]\n",
    "    fill_with=\"neutral\"\n",
    "    df=fill_na_columns(df,fill_na_sent,fill_with)\n",
    "    to_rename={\"rating\":\"Rating\"}\n",
    "    df.rename(columns=to_rename, inplace=True)\n",
    "    df=aggregate_ratings(df)\n",
    "    to_rename={\"Rating\":\"rating\"}\n",
    "    df.rename(columns=to_rename, inplace=True)\n",
    "    new_order=[\"review\",\"rating\",\"sbjText\",\"actText\",\"actVerbNeg\",\"objText\",\"locText\",\"sbjSentType\",\n",
    "               \"objSentType\",\"objSentFromSbjType\",\"locSentType\",\"sbjSentScore\",\"objSentScore\",\n",
    "               \"objSentFromSbjScore\",\"actVerbText\",\"locSentScore\",\"actLemma\",\"actVerbTense\"]    \n",
    "    df = reorder_column(df,new_order)\n",
    "    to_drop=[\"Unnamed: 0\",\"actLemma\",\"actVerbText\",\"locSentScore\",\"actVerbTense\",\n",
    "             \"locSentType\",\"locText\",\"review\",\"objSentFromSbjScore\",\"objSentFromSbjType\"]\n",
    "    to_drop=[\"Unnamed: 0\"]\n",
    "    df=drop_columns(to_drop,df)\n",
    "    return df\n",
    "\n",
    "     \n",
    "def aggregate_ratings(df):\n",
    "    conditions=[((df[\"Rating\"] >= 5) & (df[\"Rating\"] <= 6),\"good\"),\n",
    "                ((df[\"Rating\"] >= 3) & (df[\"Rating\"] <= 4),\"medium\"),\n",
    "                ((df[\"Rating\"] >= 1) & (df[\"Rating\"] <= 2),\"bad\")]\n",
    "    for condition in conditions:\n",
    "        df[\"Rating\"][condition[0]]=condition[1]\n",
    "    return df \n",
    "\n",
    "def find_keywords_in_text(df, top_bad):\n",
    "    \"\"\"\n",
    "    Finds phrases that contains keywords and aggregates then according to similar issues. \n",
    "    ++> Must manually fill in 'interesting' dictionary with interesting and non interesting top keywords words.\n",
    "    ++> Must manually aggregate interesting keywords in aggr_keywords dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    count=0\n",
    "    interesting={\"food\": 1,\"people\": 1,\"cruise line\": 0,\"msc\": 0,\n",
    "                     \"dining room\": 1,\"worst cruise\": 0,\"ship\": 1,\"cruise\": 0,\n",
    "                     \"cruise ship\": 1,\"room service\": 1,\"msc cruise\": 0,\"poor quality\": 1,\n",
    "                     \"customer service\": 1,\"passengers\": 1,\"time\": 1,\"poor service\": 1,\n",
    "                     \"board\": 1,\"bar service\": 1,\"buffet\": 1,\"cruise lines\": 0,                     \n",
    "                     \"buffet\":1,\"cruise lines\":0,\"cruise director\":1,\"table\":1,\n",
    "                     \"bar staff\":1,\"poor food\":1,\"times\":1,\"waiter\":1,\"public areas\":1,\n",
    "                     \"credit card\":0,\"food quality\":1,\"biggest disappointment\":0}\n",
    "    aggr_keywords={\"food\": \"food\",\"poor food\":\"food\",\"buffet\":\"food\",\"food quality\":\"food\",\n",
    "                   \"people\": \"people\",\"passengers\":\"people\",\n",
    "                   \"time\": \"time\",\"times\": \"time\",\n",
    "                   \"dining room\": \"dining\",\"table\":\"dining\",\"waiter\":\"dining\", \"room service\": \"dining\",\n",
    "                   \"bar service\": \"bar\",\"bar staff\":\"bar\",        \n",
    "                    \"ship\": \"ship\",\"cruise ship\": \"ship\",\"board\": \"ship\",\"public areas\":\"ship\",             \n",
    "                    \"poor quality\": \"service\",\"customer service\": \"service\",\"poor service\": \"service\",\"cruise director\":\"service\"}  \n",
    "    count=0\n",
    "    text_columns=[\"objText\",\"sbjText\",\"actVerbText\"]\n",
    "    for word in top_bad[\"Word\"]:\n",
    "        if interesting[word]==1:\n",
    "            count=count + 1\n",
    "            print \"processing\",word,\"total = \", count\n",
    "            for column in text_columns:\n",
    "                df.loc[df[column].str.contains(word), \"foundKeyword\"] = word\n",
    "                df.loc[df[column].str.contains(word), \"aggKeyword\"] = aggr_keywords[word]\n",
    "    df=df[pd.notnull(df[\"foundKeyword\"])]\n",
    "    df[\"count\"]=1\n",
    "    save_csv(df,\"data/relations_cleaned\")\n",
    "    mask=df.actVerbNeg!=1\n",
    "    df=delete_useless_rows(mask,df)\n",
    "    df[\"message\"]=df[\"sbjText\"]+\" \"+df[\"actText\"]+\" \"+df[\"objText\"]\n",
    "    df=df.reset_index()\n",
    "    to_drop=[\"review\",\"locText\",\"actVerbNeg\",\"actLemma\",\"actVerbTense\",\"actText\", \"sbjText\",\"objText\",\n",
    "             \"foundKeyword\",\"locSentType\",\"locSentScore\",\"objSentFromSbjType\",\"objSentFromSbjScore\"]\n",
    "    df=drop_columns(to_drop,df)\n",
    "    new_order=[\"rating\",\"aggKeyword\",\"message\",\"actVerbText\",\"sbjSentType\",\n",
    "               \"objSentType\",\"sbjSentScore\",\"objSentScore\",\"count\"]    \n",
    "    df = reorder_column(df,new_order)\n",
    "    to_rename={\"rating\":\"Rating\",\"aggKeyword\":\"AggKeyword\",\"message\":\"Message\",\"actVerbText\":\"ActVerbText\",\n",
    "                \"sbjSentType\":\"SbjSentType\",\"objSentType\":\"ObjSentType\",\"sbjSentScore\":\"SbjSentScore\",\n",
    "                \"objSentScore\":\"ObjSentScore\",\"count\":\"Count\"}\n",
    "    df.rename(columns=to_rename, inplace=True)\n",
    "    save_csv(df,\"relations_small\")\n",
    "    return df\n",
    "\n",
    "\n",
    "cruiseLines=[\"Msc\"]\n",
    "\n",
    "def main():\n",
    "\n",
    "    commentDb=open_json_review_files(cruiseLines)\n",
    "    commentDb=cleanRatings(commentDb,cruiseLines)\n",
    "    returned_keywords,returned_relations=checkDailyQuotaAndRunAlchemy(commentDb,cruiseLines) \n",
    "    make_keywords_csv_alchemy(returned_keywords,commentDb)\n",
    "    make_relations_csv_alchemy(returned_relations,commentDb)\n",
    "    top_keywords=30\n",
    "    df=prepare_relations()\n",
    "    top_bad=make_top_dataframes(top_keywords,cruiseLines[0])\n",
    "    print top_bad\n",
    "    df=find_keywords_in_text(df, top_bad)    \n",
    "    print df.info()\n",
    "    \n",
    "main()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
